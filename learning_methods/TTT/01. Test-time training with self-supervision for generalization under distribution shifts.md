---
author:
  - Yu Sun
  - Xiaolong Wang
  - Zhuang Liu
  - John Miller
  - Alexei Efros
  - Moritz Hardt
submission:
  - Proceedings of the 37th International Conference on Machine Learning
  - PMLR 119:9229-9248
year: "2020"
file:
  - "[[learning_methods/TTT/paper/01. Test-time training with self-supervision for generalization under distribution shifts.pdf|01. Test-time training with self-supervision for generalization under distribution shifts]]"
related: 
tags:
  - Test-Time-Training
review date: 2024-11-12
---
# <font color="#31859b">Summary</font>

## 1-Line

```
Test-Time Training (TTT)은 테스트 시점에서 self-supervised learning을 통해 모델을 업데이트하여 distribution shift에 대한 일반화 성능을 향상시키는 방법을 제안 [p.1, Introduction]
```
## 3-Line

```
테스트 샘플을 self-supervised learning 문제로 변환하여 테스트 시점에서 모델을 업데이트 [p.1, Introduction]
```

```
모델이 메인 태스크와 self-supervised 태스크에 하나의 feature extractor를 공유하도록 설계 [p.2, Method]
```

```
??
```
## 5-Line

```
Traditional supervised learning은 distribution shift에 취약한 문제 존재 [p.1, Introduction]
```

```
TTT는 테스트 샘플의 distribution 정보를 활용하여 테스트 시점에서 모델을 업데이트 [p.1-2, Introduction]
```

```
Self-supervised learning을 auxiliary task로 활용하여 라벨 없이 모델을 업데이트 [p.2, Method]
```

```
Online TTT는 연속적으로 들어오는 테스트 샘플들에 대해 점진적으로 모델을 업데이트 [p.2, Method]
```

```
다양한 distribution shift 벤치마크에서 성능 향상을 확인됨 [p.3-7, Empirical Results]
```


# <font color="#7030a0">Paper Review</font>

## Abstract / Motivation

> 머신 러닝의 일반화 성능을 저하 시키는 주요 문제인 Distribution-Shift 해결

```
"Supervised learning remains notoriously weak at generalization under distribution shifts. Unless training and test data are drawn from the same distribution, even seemingly minor differences turn out to defeat state-of-the-art models." [p.1, Abstract]
```

* 기존의 다른 연구들이 제안한 Training 시점에서의 다양한 Distribution 고려, 특히 Test Distribution에 대한 적응 방식의 한계를 인식하고 자가지도학습(Self-Supervised Learning)을 테스트 시점에 수행하는 방식을 제안

## Background

> 기존 연구들은 학습 시점에 테스트 도메인에 대한 적응력을 높이는 방향으로 해결책을 주로 제안하였으나,  한계가 있었음.

- Distribution shift: Training과 test 데이터의 distribution이 다른 상황

	원문: "We start from a simple observation. The unlabeled test sample x presented at test time gives us a hint about the distribution from which it was drawn." [p.1, Introduction]

	- 쟁점: 사소해 보이는 분포 차이도 테스트 시의 모델 성능을 크게 해칠 수 있음

		원문: "Unless training and test data are drawn from the same distribution, even seemingly minor differences turn out to defeat state-of-the-art models." [p.1, Abstract]

- Self-supervised learning: 데이터로부터 생성된 supervision을 활용하는 학습 방법

	"Self-supervised learning uses an auxiliary task that automatically creates labels from unlabeled inputs." [p.2, Method]

	* 한계: 기존의 self-supervised learning은 training time에만 적용되어 test time에서의 distribution shift에 대응하지 못함

		원문: "Closely related to our work, Hendrycks et al. (2019a) propose that jointly training a main task and a self-supervised task can improve robustness on the main task." [p.9, Related Work]

- Domain adaptation: Source domain에서 Target domain으로의 지식 전이

	"Unsupervised domain adaptation studies the problem of distribution shifts, when an unlabeled dataset from the test distribution (target domain) is available at training time" [p.9, Related Work]

	* 한계: 도메인 적응의 대상이 사전에 준비된 특정 테스트 분포에 대해서만 적용할 수 있고, 그러한 테스트 분포는 예측으로 생성해내기 힘듬 => 전반적인 일반화를 이끌어내지 못함

		* 도메인 적응은 training time에 target domain의 데이터가 필요
		- 적응하고자 하는 target domain을 미리 알아야 함
		- 하지만 실제 상황에서는 어떤 distribution shift가 발생할지 미리 알기 어려움

		원문: "The limitation of the problem setting, however, is that generalization might only be improved for this specific test distribution, which can be difficult to anticipate in advance." [p.9, Related Work]

	* 아이디어 도출: 테스트 타임에도 학습을 진행하면, 자기 지도의 알고리즘의 영감을 가져가면서도, 도메인 적응 설정은 변경하기 때문에 어떠한 테스트 분포도 미리 예측하지 않을 수 있음

		* 특정 테스트 분포를 미리 알 필요 없이, test time에 실제 마주치는 distribution shift에 대해 적응할 수 있다는 장점

		원문: "Test-Time Training does not anticipate any test distribution, by changing the setting of unsupervised domain adaptation, while taking inspiration from its algorithms." [p.9, Related Work]

## Targetting Problems

> Test time에서 target domain에 대한 사전 정보나 라벨 없이도, 다양한 distribution shift에 효과적으로 대응

```
"We explore a new take on generalization that does not anticipate the distribution shifts, but instead learns from them at test time." [p.1, Introduction]
```

- Supervised learning의 distribution shift에 대한 취약성
- 테스트 시점에서 라벨 없이 모델을 업데이트해야 하는 제약
- 다양하고 예측 불가능한 distribution shift에 대한 일반화 필요성

## Suggestions / Methods

> 테스트 샘플에 대해 rotation prediction과 같은 self-supervised task를 수행하면서 얻은 loss로 feature extractor를 업데이트하여, 라벨 없이도 해당 테스트 샘플의 분포 특성을 학습할 수 있게 함

- Feature extractor 공유 구조 설계: "The auxiliary task shares some of the model parameters θe = (θ1, ..., θκ) up to a certain κ ∈ {1, ..., K}. We designate those κ layers as a shared feature extractor. [p.2, Method]

	- 모델의 초반 κ개 층을 main task와 self-supervised task가 공유
	- Y-구조: 하단부는 공유하고 상단부는 각 task별 별도 branch
	- 이를 통해 self-supervised task에서 학습한 특징이 main task에도 도움이 되게 함

- Self-supervised task를 통한 모델 업데이트: "In our experiments, we use the task of rotating each input image by a multiple of 90 degrees and predicting its angle" [p.1, Introduction]

	- 테스트 이미지를 회전시켜 그 각도를 예측하는 self-supervised task 수행
	- 이 과정에서 얻은 loss로 shared feature extractor 업데이트
	- 실제 예측은 업데이트된 feature extractor를 사용

- Online version의 점진적 적응: "If samples arrive in an online stream, we obtain further improvements by keeping the state of the parameters." [p.1, Introduction]

	- 연속적으로 들어오는 테스트 샘플들에 대해 이전 업데이트 상태를 유지
	- 점진적으로 변화하는 distribution shift에 대응 가능
	- 각 샘플마다 한 번의 gradient step만 수행

* 참고) Gradient correlation 분석:
	* Main task와 self-supervised task의 gradient 사이의 상관관계 분석
	* Gradient correlation이 양수일 때 성능 향상 보장
