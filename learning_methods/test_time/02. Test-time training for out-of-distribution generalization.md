---
author:
  - Yu Sun
  - Xiaolong Wang
  - Zhuang Liu
  - John Miller
  - Alexei A. Efros
  - Moritz Hardt
submission:
  - ICLR 2020 Conference Blind Submission
year: "2019"
file:
  - "[[learning_methods/test_time/paper/02. Test-Time Training for Out-of-Distribution Generalization.pdf|02. Test-Time Training for Out-of-Distribution Generalization]]"
related: 
tags:
  - Test-Time-Training
review date: 2024-11-12
---
# <font color="#31859b">Summary</font>

## 1-Line

```
Test-time training은 테스트 데이터의 분포가 학습 데이터와 다를 때 self-supervised learning을 통해 단일 테스트 샘플에 대해 모델을 추가 학습시켜 예측 성능을 향상시키는 기법 [Abstract, p.1]
```
## 3-Line

```
Test-time training은 테스트 시점에 단일 샘플을 활용한 self-supervised learning을 통해 모델을 추가 학습시키는 방법을 제안 [Abstract, p.1]
```

```
이미지 회전 예측과 같은 보조 작업을 통해 테스트 샘플의 분포 정보를 학습하여 성능을 개선 [Section 2 Method, p.2]
```

```
CIFAR-10, ImageNet 등 다양한 데이터셋에서 corruption과 distribution shift에 대한 robustness가 크게 향상 [Section 3 Empirical Results, p.3-5]
```
## 5-Line

```
학습된 feature extractor를 공유하여 원래 task의 성능도 함께 개선 [Section 2 Method, p.2]
```


# <font color="#7030a0">Paper Review</font>

## Abstract / Motivation

> Distribution shift 문제를 해결하기 위한 새로운 접근 방식으로 test-time training을 제안 [Abstract, p.1]
> 
> Test-time training은 테스트 샘플을 self-supervised learning 문제로 변환하여 모델을 추가 학습 [Abstract, p.1]

## Background

> 기존의 supervised learning은 학습과 테스트 데이터의 분포가 다를 때 성능이 저하되는 문제 존재 [Section 1 Introduction, p.1]
> 
> Transfer learning, domain adaptation, adversarial robustness 등 기존 방법들은 사전에 알려진 distribution shift에 대해서만 대응이 가능 [Section 1 Introduction, p.1]

## Targeting Problems

- Distribution shift로 인한 성능 저하 문제 [Section 1 Introduction, p.1]
- 사전에 알려지지 않은 distribution shift에 대한 대응 문제 [Section 1 Introduction, p.1]
- 테스트 시점에서의 모델 적응 문제 [Section 1 Introduction, p.1-2]

## Suggestions / Methods

- Self-supervised learning을 통한 test-time training [Section 2 Method, p.2]
- Feature extractor 공유를 통한 성능 향상 [Section 2 Method, p.2]
- Online test-time training을 통한 연속적인 성능 개선 [Section 2 Method - Online version, p.2]

