---
author:
  - A
  - B
submission:
  - PMIR
  - B
year: "2024"
file: 
related: 
tags: []
review date: 2025-01-03
---
# <font color="#31859b">Summary</font>

## 1-Line

>"Test-time adaptation (TTA), an emerging paradigm, has the potential to adapt a pre-trained model to unlabeled data during testing, before making predictions."

```
Test-time adaptation (TTA)은 사전 학습된 모델을 테스트 시점에 레이블이 없는 데이터에 적응시키는 새로운 패러다임 [p.1, Abstract]
```
## 3-Line

>"This survey primarily focuses on the paradigm of test-time adaptation (TTA), which involves adapting a pre-trained model from the source domain to unlabeled data in the target domain before making predictions"

```
TTA는 source 데이터 없이 target 도메인의 unlabeled 데이터만을 사용하여 모델을 적응  [p.1, Introduction]
```

>"Based on the characteristics of the test data, TTA methods can be categorized into three distinct cases in Fig. 1: test-time domain adaptation (TTDA), test-time batch adaptation (TTBA), and online test-time adaptation (OTTA)"

```
TTA는 테스트 데이터 형태에 따라 test-time domain adaptation (TTDA), test-time batch adaptation (TTBA), online test-time adaptation (OTTA)로 구분  [p.2, Introduction]
```

>"Firstly, TTDA...utilizes all m test batches for multi-epoch adaptation before generating final predictions. Secondly, TTBA individually adapts...Thirdly, OTTA adapts the pre-trained model to the target data {b1, ··· , bm} in an online manner"

```
각 카테고리별로 서로 다른 적응 전략과 목표를 가짐 [p.2, Introduction]
```
## 5-Line

>"This survey primarily focuses on the paradigm of test-time adaptation (TTA), which involves adapting a pre-trained model from the source domain to unlabeled data in the target domain before making predictions"

```
TTA는 source 데이터 없이 target 도메인의 unlabeled 데이터만을 사용하여 모델을 적응  [p.1, Introduction]
```

>"Based on the characteristics of the test data, TTA methods can be categorized into three distinct cases in Fig. 1: test-time domain adaptation (TTDA), test-time batch adaptation (TTBA), and online test-time adaptation (OTTA)"

```
TTA는 테스트 데이터 형태에 따라 test-time domain adaptation (TTDA), test-time batch adaptation (TTBA), online test-time adaptation (OTTA)로 구분  [p.2, Introduction]
```

>"Firstly, TTDA...utilizes all m test batches for multi-epoch adaptation before generating final predictions. Secondly, TTBA individually adapts...Thirdly, OTTA adapts the pre-trained model to the target data {b1, ··· , bm} in an online manner"

```
각 카테고리별로 서로 다른 적응 전략과 목표를 가짐 [p.2, Introduction]
```

>"which can be prohibitive in privacy-sensitive applications such as medical data"

```
TTA는 privacy-sensitive한 응용에서 특히 유용합니다. source 데이터 접근이 제한되는 의료 데이터와 같은 경우에 적합 [p.2, Introduction]
```

>"To our knowledge, this is the first survey that provides a systematic overview of three distinct topics within the broad test-time adaptation paradigm"

```
본 연구는 TTA 분야의 첫 체계적인 서베이로서, 각 하위 분야별 최신 알고리즘들을 분류하고 다양한 응용 사례들을 분석 [p.2, Introduction]
```

# <font color="#7030a0">Paper Review</font>

## Abstract / Motivation

> "Machine learning methods strive to acquire a robust model during the training process that can effectively generalize to test samples, even in the presence of distribution shifts. However, these methods often suffer from performance degradation due to unknown test distributions"

- 기존 머신러닝 방법들은 training과 test 데이터가 동일한 분포를 따른다고 가정하지만, 실제로는 distribution shift가 발생하여 성능 저하가 발생 [p.1, Abstract]

>"TTA has the advantage of being able to access test data from the target domain during the test phase...TTA only requires access to the pre-trained model from the source domain"

- 이를 해결하기 위한 방법으로 TTA가 제안되었으며, source 데이터 없이도 target 도메인에 적응할 수 있는 장점이 있음 [p.2, Introduction]
## Background

도메인 적응의 기존 방법들:

1. Domain Generalization (DG)
2. Domain Adaptation (DA)
3. Hypothesis Transfer Learning (HTL)

이들과 비교했을 때 TTA의 주요 차별점은:

1. DG와 달리 테스트 데이터 활용 가능 [p.1 Introduction]
2. DA와 달리 source 데이터 불필요 [p.1-2 Introduction]
3. HTL과 달리 target 도메인의 레이블 데이터 불필요 [p.3 Section 2.2]

## Targeting Problems

1. Distribution Shift 문제
	- Covariate Shift: 입력 특성이 레이블을 결정하는 경우의 분포 변화 [p.3, Section 2.1: "covariate shift in which the input features cause the labels"]
	- Label Shift: 출력 레이블이 특성을 결정하는 경우의 분포 변화 [p.3, Section 2.1: "label shift in which the output labels cause the features"]

	- 실제 예시: 다른 카메라로 촬영된 이미지, 다른 도시의 도로 장면, 다른 병원의 의료영상 등 [p.1, Introduction: "such as images captured by different cameras, road scenes of different cities, and imaging devices in different hospitals"]

2. Privacy 제약 문제
	- 의료 데이터와 같은 민감한 데이터의 경우 source 데이터 공유가 제한됨 [p.2, Introduction: "which can be prohibitive in privacy-sensitive applications such as medical data"]
	- 기존 DA 방법들은 source와 target 데이터를 동시에 필요로 하여 적용이 어려움 [p.1-2, Introduction: "DA typically necessitates access to both labeled data from the source domain and (unlabeled) data from the target domain simultaneously"]

3. Online/Streaming 환경 문제
	- 실시간으로 들어오는 데이터에 대한 즉각적인 적응 필요 [p.2, Introduction]
	- 데이터 분포가 시간에 따라 변화할 수 있음 [p.18-19, Section 5.3: "test samples at test time may come from a variety of different distributions"]
	- 이전 데이터를 저장하거나 재사용하기 어려운 제약 존재 [p.2, Introduction: "where each mini-batch can only be observed once"]

## Suggestions / Methods

1. TTDA (Test-Time Domain Adaptation)
    - Pseudo-Labeling: **신뢰할 수 있는 pseudo label 생성 및 활용** [p.4 Section 3.2.1]
    - Consistency Training: 입력 변형에 대한 일관성 유지 [p.7-8 Section 3.2.2]
    - Clustering-Based Training: 클러스터링을 통한 feature 학습 [p.9 Section 3.2.3]
    - Source Distribution Estimation: source 분포 추정을 통한 적응 [p.10 Section 3.2.4]

2. TTBA (Test-Time Batch Adaptation)
    - BN Calibration: **배치 정규화 통계량 조정** [p.14 Section 4.2.1]
    - Model Optimization: 모델 파라미터 최적화 [p.15 Section 4.2.2]
    - Meta-Learning: 메타학습을 통한 빠른 적응 [p.16 Section 4.2.3]
    - Input Adaptation: 입력 데이터 조정 [p.17 Section 4.2.4]

3. OTTA (Online Test-Time Adaptation)
    - Entropy Minimization: 엔트로피 최소화를 통한 적응 [p.19 Section 5.2.2]
    - Consistency Regularization: 일관성 정규화 [p.20 Section 5.2.4]
    - Anti-forgetting Regularization: 이전 지식 유지 [p.20-21 Section 5.2.5]
    - Dynamic Inference: 동적 추론 방식 활용 [p.17-18 Section 4.2.5]


<각 방법론의 특징적인 구현 사례>:
	- SHOT: Centroid-based pseudo labeling을 통한 TTDA [p.5 Table 1]
	- Tent: Entropy minimization을 통한 OTTA [p.19 Section 5.2.2]
	- MEMO: 다중 augmentation을 활용한 TTBA [p.15-16 Section 4.2.2]
	