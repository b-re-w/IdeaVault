## Paper review index for Transformer-based Archtectures

#### Language Model

| Index                                                                               | Title & Link                                                                                                 | Paper                                                                                   | Submission | Year |
| ----------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------ | --------------------------------------------------------------------------------------- | ---------- | ---- |
| [[L01. Learning to (Learn at Test Time) - RNNs with Expressive Hidden States\|L01]] | [Learning to (learn at **test time**): Rnns with expressive hidden states](https://arxiv.org/abs/2407.04620) | [[L01. Learning to (Learn at Test Time) - RNNs with Expressive Hidden States.pdf\|pdf]] | #Pre-Print | 2024 |
| L02                                                                                 | [Byte Latent Transformer: Patches Scale Better Than Tokens](https://arxiv.org/abs/2412.09871)                | [[L02. Byte Latent Transformer - Patches Scale Better Than Tokens.pdf\|pdf]]            | #Pre-Print | 2024 |
|                                                                                     |                                                                                                              |                                                                                         |            |      |


#### Vision Model

| Index                                | Title & Link                                                                                                                                                                                                                                    | Paper                                                                                                 | Submission | Year |
| ------------------------------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------- | ---------- | ---- |
| V01                                  | [An image is worth 16x16 words: Transformers for image recognition at scale](https://arxiv.org/abs/2010.11929)                                                                                                                                  | [[V01. An image is worth 16x16 words - Transformers for image recognition at scale.pdf\|pdf]]         | #Pre-Print | 2021 |
| **<font color="#c0504d">V02</font>** | [**End**-**to**-**end object detection** with **transformers**](https://arxiv.org/abs/2005.12872)                                                                                                                                               | [[V02. End-to-End Object Detection with Transformers.pdf\|pdf]]                                       | #EECV      | 2020 |
| V03                                  | [Deformable **DETR**: # Deformable Transformers for End-to-End Object Detection](https://arxiv.org/abs/2010.04159)                                                                                                                              | [[V03. Deformable DETR - Deformable Transformers for End-to-End Object Detection.pdf\|pdf]]           | #Pre-Print | 2021 |
| V04                                  | [Dynamic **DETR**: End-to-End Object Detection With Dynamic Attention](https://openaccess.thecvf.com/content/ICCV2021/html/Dai_Dynamic_DETR_End-to-End_Object_Detection_With_Dynamic_Attention_ICCV_2021_paper.html?ref=https://githubhelp.com) | [[V04. Dynamic DETR - End-to-End Object Detection With Dynamic Attention.pdf\|pdf]]                   | #ICCV      | 2021 |
| v05                                  | [UP-**DETR**: Unsupervised Pre-Training for Object Detection With Transformers](http://openaccess.thecvf.com/content/CVPR2021/html/Dai_UP-DETR_Unsupervised_Pre-Training_for_Object_Detection_With_Transformers_CVPR_2021_paper.html)           | [[V05. UP-DETR - Unsupervised Pre-Training for Object Detection With Transformers.pdf\|pdf]]          | #CVPR      | 2021 |
| **<font color="#c0504d">V06</font>** | [DINO: **DETR** with Improved DeNoising Anchor Boxes for End-to-End Object Detection](https://arxiv.org/abs/2203.03605)                                                                                                                         | [[V06. DINO - DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection.pdf\|pdf]]    | #Pre-Print | 2022 |
| **<font color="#c0504d">V07</font>** | [DINOv2: Learning Robust Visual Features without Supervision](https://arxiv.org/abs/2304.07193)                                                                                                                                                 | [[V07. DINOv2 - Learning Robust Visual Features without Supervision.pdf\|pdf]]                        | #Pre-Print | 2024 |
| 10                                   | ### [Efficient **detr**: improving end-to-end object detector with dense prior](https://arxiv.org/abs/2104.01318)                                                                                                                               |                                                                                                       |            | 2021 |
| 11                                   | ### [Dab-**detr**: Dynamic anchor boxes are better queries for **detr**](https://arxiv.org/abs/2201.12329)                                                                                                                                      |                                                                                                       |            | 2022 |
| 12                                   | ### [Sparse **detr**: Efficient end-to-end object detection with learnable sparsity](https://arxiv.org/abs/2111.14330)                                                                                                                          |                                                                                                       |            | 2022 |
| 13                                   | ### [Co-DETR: **DETR**s with Collaborative Hybrid Assignments Training](http://openaccess.thecvf.com/content/ICCV2023/html/Zong_DETRs_with_Collaborative_Hybrid_Assignments_Training_ICCV_2023_paper.html)                                      |                                                                                                       |            | 2023 |
| **<font color="#c0504d">V14</font>** | [**DETR**s Beat YOLOs on Real-time Object Detection](http://openaccess.thecvf.com/content/CVPR2024/html/Zhao_DETRs_Beat_YOLOs_on_Real-time_Object_Detection_CVPR_2024_paper.html)                                                               | [[V14. DETRs Beat YOLOs on Real-time Object Detection.pdf\|pdf]]                                      | #CVPR      | 2024 |
| **V15**                              | PVT2                                                                                                                                                                                                                                            |                                                                                                       |            |      |
| **V16**                              | Twins                                                                                                                                                                                                                                           |                                                                                                       |            |      |
| **V17**                              | [Swin Transformer - Hierarchical Vision Transformer Using Shifted Windows](https://openaccess.thecvf.com/content/ICCV2021/html/Liu_Swin_Transformer_Hierarchical_Vision_Transformer_Using_Shifted_Windows_ICCV_2021_paper)                      | [[V17. Swin Transformer - Hierarchical Vision Transformer Using Shifted Windows.pdf\|pdf]]            | #ICCV      | 2022 |
| **V18**                              | [SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers](https://arxiv.org/abs/2105.15203)                                                                                                                          | [[V18. SegFormer - Simple and Efficient Design for Semantic Segmentation with Transformers.pdf\|pdf]] | #NeurIPS   |      |
| **<font color="#c0504d">V19</font>** | [CG ViT: **Global Context Vision Transformers**](https://proceedings.mlr.press/v202/hatamizadeh23a.html)                                                                                                                                        | [[V19. CG ViT - Global Context Vision Transformer.pdf\|pdf]]                                          | #PMLR      | 2023 |
| V20                                  | DynamicViT                                                                                                                                                                                                                                      |                                                                                                       |            |      |
| **V21**                              | [**Focal** Self-attention for Local-Global Interactions in Vision **Transformers**](https://arxiv.org/abs/2107.00641)                                                                                                                           | [[V21. Focal Self-attention for Local-Global Interactions in Vision Transformers.pdf\|pdf]]           | #NeurIPS   | 2022 |
| V22                                  | CSWin Transformer                                                                                                                                                                                                                               |                                                                                                       |            |      |
| V23                                  | MaxViT                                                                                                                                                                                                                                          |                                                                                                       |            |      |
| V24                                  | MinViT                                                                                                                                                                                                                                          |                                                                                                       |            |      |
| V25                                  | InternImage                                                                                                                                                                                                                                     |                                                                                                       |            |      |
| **V26**                              | UFO (Unified Feature Optimization) Transformer                                                                                                                                                                                                  |                                                                                                       |            |      |
| **V27**                              | [LaVin-DiT: Large Vision Diffusion Transformer](https://arxiv.org/abs/2411.11505)                                                                                                                                                               | [[V27. LaVin-DiT - Large Vision Diffusion Transformer.pdf\|pdf]]                                      | #Pre-Print | 2024 |
|                                      |                                                                                                                                                                                                                                                 |                                                                                                       |            |      |
![[segformer_eval.png]]

확인해야 할 것:
- DA-Transformer - https://velog.io/@jody1188/DA-Transformer-Distance-aware-Transformer
- Paged Attention - https://velog.io/@jminj/Paged-Attention

#### Linear Attention

| Index | Title & Link       | Paper | Submission | Year |
| ----- | ------------------ | ----- | ---------- | ---- |
|       | Linformer          |       |            |      |
|       | Linear Transformer |       |            |      |
|       | Performer          |       |            |      |
|       |                    |       |            |      |
https://velog.io/@jody1188/Linear-Complexity-Attention
