## Paper review index for Transformer-based Archtectures

#### Language Model

| Index                                                                             | Title & Link                                                                                                 | Paper                                                                                  | Submission | Year |
| --------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------ | -------------------------------------------------------------------------------------- | ---------- | ---- |
| [[01. Learning to (Learn at Test Time) - RNNs with Expressive Hidden States\|01]] | [Learning to (learn at **test time**): Rnns with expressive hidden states](https://arxiv.org/abs/2407.04620) | [[01. Learning to (Learn at Test Time) - RNNs with Expressive Hidden States.pdf\|pdf]] | #Pre-Print | 2024 |
| 02                                                                                | [Byte Latent Transformer: Patches Scale Better Than Tokens](https://arxiv.org/abs/2412.09871)                | [[02. Byte Latent Transformer - Patches Scale Better Than Tokens.pdf\|pdf]]            | #Pre-Print | 2024 |
|                                                                                   |                                                                                                              |                                                                                        |            |      |


#### Vision Model

| Index  | Title & Link                                                                                                                                                                                                                                    | Paper                                                                                                | Submission | Year |
| ------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------- | ---------- | ---- |
| 03     | [An image is worth 16x16 words: Transformers for image recognition at scale](https://arxiv.org/abs/2010.11929)                                                                                                                                  | [[03. An image is worth 16x16 words - Transformers for image recognition at scale.pdf\|pdf]]         | #Pre-Print | 2021 |
| **04** | [**End**-**to**-**end object detection** with **transformers**](https://arxiv.org/abs/2005.12872)                                                                                                                                               | [[04. End-to-End Object Detection with Transformers.pdf\|pdf]]                                       | #EECV      | 2020 |
| 05     | [Deformable **DETR**: # Deformable Transformers for End-to-End Object Detection](https://arxiv.org/abs/2010.04159)                                                                                                                              | [[05. Deformable DETR - Deformable Transformers for End-to-End Object Detection.pdf\|pdf]]           | #Pre-Print | 2021 |
| 06     | [Dynamic **DETR**: End-to-End Object Detection With Dynamic Attention](https://openaccess.thecvf.com/content/ICCV2021/html/Dai_Dynamic_DETR_End-to-End_Object_Detection_With_Dynamic_Attention_ICCV_2021_paper.html?ref=https://githubhelp.com) | [[06. Dynamic DETR - End-to-End Object Detection With Dynamic Attention.pdf\|pdf]]                   | #ICCV      | 2021 |
| 07     | [UP-**DETR**: Unsupervised Pre-Training for Object Detection With Transformers](http://openaccess.thecvf.com/content/CVPR2021/html/Dai_UP-DETR_Unsupervised_Pre-Training_for_Object_Detection_With_Transformers_CVPR_2021_paper.html)           | [[07. UP-DETR - Unsupervised Pre-Training for Object Detection With Transformers.pdf\|pdf]]          | #CVPR      | 2021 |
| **08** | [DINO: **DETR** with Improved DeNoising Anchor Boxes for End-to-End Object Detection](https://arxiv.org/abs/2203.03605)                                                                                                                         | [[08. DINO - DETR with Improved DeNoising Anchor Boxes for End-to-End Object Detection.pdf\|pdf]]    | #Pre-Print | 2022 |
| **09** | [DINOv2: Learning Robust Visual Features without Supervision](https://arxiv.org/abs/2304.07193)                                                                                                                                                 | [[09. DINOv2 - Learning Robust Visual Features without Supervision.pdf\|pdf]]                        | #Pre-Print | 2024 |
| 10     | ### [Efficient **detr**: improving end-to-end object detector with dense prior](https://arxiv.org/abs/2104.01318)                                                                                                                               |                                                                                                      |            | 2021 |
| 11     | ### [Dab-**detr**: Dynamic anchor boxes are better queries for **detr**](https://arxiv.org/abs/2201.12329)                                                                                                                                      |                                                                                                      |            | 2022 |
| 12     | ### [Sparse **detr**: Efficient end-to-end object detection with learnable sparsity](https://arxiv.org/abs/2111.14330)                                                                                                                          |                                                                                                      |            | 2022 |
| 13     | ### [Co-DETR: **DETR**s with Collaborative Hybrid Assignments Training](http://openaccess.thecvf.com/content/ICCV2023/html/Zong_DETRs_with_Collaborative_Hybrid_Assignments_Training_ICCV_2023_paper.html)                                      |                                                                                                      |            | 2023 |
| **14** | [**DETR**s Beat YOLOs on Real-time Object Detection](http://openaccess.thecvf.com/content/CVPR2024/html/Zhao_DETRs_Beat_YOLOs_on_Real-time_Object_Detection_CVPR_2024_paper.html)                                                               | [[14. DETRs Beat YOLOs on Real-time Object Detection.pdf\|pdf]]                                      | #CVPR      | 2024 |
| **15** | PVT2                                                                                                                                                                                                                                            |                                                                                                      |            |      |
| **16** | Twins                                                                                                                                                                                                                                           |                                                                                                      |            |      |
| **17** | [Swin Transformer - Hierarchical Vision Transformer Using Shifted Windows](https://openaccess.thecvf.com/content/ICCV2021/html/Liu_Swin_Transformer_Hierarchical_Vision_Transformer_Using_Shifted_Windows_ICCV_2021_paper)                      | [[17. Swin Transformer - Hierarchical Vision Transformer Using Shifted Windows.pdf\|pdf]]            | #ICCV      | 2022 |
| **18** | [SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers](https://arxiv.org/abs/2105.15203)                                                                                                                          | [[18. SegFormer - Simple and Efficient Design for Semantic Segmentation with Transformers.pdf\|pdf]] | #NeurIPS   |      |
| **19** | [CG ViT: **Global Context Vision Transformers**](https://proceedings.mlr.press/v202/hatamizadeh23a.html)                                                                                                                                        | [[19. CG ViT - Global Context Vision Transformer.pdf\|pdf]]                                          | #PMIR      | 2023 |
| 20     | DynamicViT                                                                                                                                                                                                                                      |                                                                                                      |            |      |
| **21** | [**Focal** Self-attention for Local-Global Interactions in Vision **Transformers**](https://arxiv.org/abs/2107.00641)                                                                                                                           | [[21. Focal Self-attention for Local-Global Interactions in Vision Transformers.pdf\|pdf]]           | #NeurIPS   | 2022 |
| 22     | CSWin Transformer                                                                                                                                                                                                                               |                                                                                                      |            |      |
| 23     | MaxViT                                                                                                                                                                                                                                          |                                                                                                      |            |      |
| 24     | MinViT                                                                                                                                                                                                                                          |                                                                                                      |            |      |
| 25     | InternImage                                                                                                                                                                                                                                     |                                                                                                      |            |      |
| **26** | UFO (Unified Feature Optimization) Transformer                                                                                                                                                                                                  |                                                                                                      |            |      |
| **27** | [LaVin-DiT: Large Vision Diffusion Transformer](https://arxiv.org/abs/2411.11505)                                                                                                                                                               | [[27. LaVin-DiT - Large Vision Diffusion Transformer.pdf\|pdf]]                                      | #Pre-Print | 2024 |
|        |                                                                                                                                                                                                                                                 |                                                                                                      |            |      |
![[segformer_eval.png]]

확인해야 할 것:
- DA-Transformer - https://velog.io/@jody1188/DA-Transformer-Distance-aware-Transformer
- Paged Attention - https://velog.io/@jminj/Paged-Attention

#### Linear Attention

| Index | Title & Link       | Paper | Submission | Year |
| ----- | ------------------ | ----- | ---------- | ---- |
|       | Linformer          |       |            |      |
|       | Linear Transformer |       |            |      |
|       | Performer          |       |            |      |
|       |                    |       |            |      |
https://velog.io/@jody1188/Linear-Complexity-Attention
